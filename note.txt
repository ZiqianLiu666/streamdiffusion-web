conda activate monai
1. 先准备训练反演模型的数据集
python SwiftEdit/prepare_dataset.py

2. 训练StreamDiffusion中SD-Turbo的一步反演模型
python SwiftEdit/train_ip_s2_ldist_lnoise_v3.py \
  --data_option                stream_tsv \
  --task                       reconstruct \
  --pretrained_model_name_or_path  Manojb/stable-diffusion-2-1-base \
  --pretrained_teacher_denoise     Manojb/stable-diffusion-2-1-base \
  --pretrained_sb_generator        stabilityai/sd-turbo \
  --output_dir                     outputs/sd_turbo_stage2 \
  --image_encoder_path             h94/IP-Adapter \
  --ip_adapter_weight_name         ... \
  --logging_dir                    logs \
  --learning_rate                  1e-4 \
  --train_batch_size               1 \
  --gradient_accumulation_steps    4 \
  --validation_steps               2000 \
  --max_train_steps                50000 \
  --checkpointing_steps            2000 \
  --mixed_precision                fp16 \

1）pretrained_model_name_or_path — 用来加载 teacher 的 scheduler / VAE / text_encoder
定义训练宇宙的物理法则（VAE + text encoder + tokenizer + scheduler）.所有 latent、所有 prompt embedding，都是在这个 SD2.1 空间中运作。
2）pretrained_teacher_denoise — 只用来加载 teacher 的 UNet
老师告诉 inversion 学生“真正的噪声梯度应该是什么”.teacher 是多步模型（SD2.1 UNet），比学生更强。
3）pretrained_sb_generator — 一步生成器（Turbo）用于重建图像以计算 DISTS / LPIPS 损失。Turbo 不更新，只 forward。你的 inversion 网络就是为它服务的。
4）pretrained_ip_s1_path — IP-Adapter 的额外 cross-attention 权重。允许 Turbo + inversion 支持图像提示（image conditioning）。
5）image_encoder_path — CLIP Vision backbone，用来把输入图像转成 IP-Adapter tokens。提供额外 conditioning，例如“保持 identity”。



# StreamDiffusion中每次前端有所改变的时候，就要执行这个命令
cd frontend && npm run build




2. FlashAttention
3. 采用高级采样调度算法减少扩散步数
4. 集成扩散模型低比特量化以降低显存占用

IP-ADAPTER要修改一下，前端传参考图像。
集成IP-ADAPTER到streamdiffusion里说不定能提升LPIPS(就是提升编辑后的图和原图的相关性，不至于漂移到只和Prompt相关)

问题：
像Prompt是remove glasses, wearing red hat，结果根本不会反应。


在https://github.com/cumulo-autumn/StreamDiffusion/tree/main 这个项目的img2img中，我发现它提供的SD1.5-Turbo和SD1.5+LCM-LoRA被包装在StreamDiffusion管道中并主要对整体风格转换、轻微布局变化才有反应，其他精细化的如局部编辑并没有任何反应(例如Put glasses on the hat, Turn cat into a dog)。你觉得应该加入什么方法或创新才能实现这个效果？(加入的方法或创新被别人提出来过的都可以)。请你仔细思考，并且我给你提供了他的代码。


所以到底有没有必要加载官方发布的IP-ADAPTER权重？不加载的话会不会对训练结果有影响？
